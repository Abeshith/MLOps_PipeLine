name: Model Training & Deployment

on:
  schedule:
    # Run model training weekly (Sundays at 2 AM UTC)
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      retrain_model:
        description: 'Force model retraining'
        required: false
        default: false
        type: boolean
      data_source:
        description: 'Data source for training'
        required: false
        default: 'kaggle'
        type: choice
        options:
        - kaggle
        - local
        - s3

env:
  PYTHON_VERSION: "3.11"
  PYTHONPATH: "src"

jobs:
  data-ingestion:
    runs-on: ubuntu-latest
    name: Data Ingestion & Validation
    
    outputs:
      data-updated: ${{ steps.check-data.outputs.updated }}
      data-version: ${{ steps.version-data.outputs.version }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Setup Kaggle credentials
      run: |
        mkdir -p ~/.kaggle
        echo '${{ secrets.KAGGLE_JSON }}' > ~/.kaggle/kaggle.json
        chmod 600 ~/.kaggle/kaggle.json
      if: github.event.inputs.data_source == 'kaggle' || github.event.inputs.data_source == ''
        
    - name: Run data ingestion
      run: |
        export PYTHONPATH=src
        python -c "
        from src.mlpipeline.config.configuration import ConfigurationManager
        from src.mlpipeline.components.data_ingestion import DataIngestion
        
        config = ConfigurationManager()
        data_ingestion_config = config.get_data_ingestion_config()
        data_ingestion = DataIngestion(config=data_ingestion_config)
        data_ingestion.download_file()
        data_ingestion.extract_zip_file()
        print('Data ingestion completed successfully')
        "
        
    - name: Run data validation
      run: |
        export PYTHONPATH=src
        python -c "
        from src.mlpipeline.config.configuration import ConfigurationManager
        from src.mlpipeline.components.data_validation import DataValidation
        
        config = ConfigurationManager()
        data_validation_config = config.get_data_validation_config()
        data_validation = DataValidation(config=data_validation_config)
        data_validation.validate_all_columns()
        print('Data validation completed successfully')
        "
        
    - name: Check if data updated
      id: check-data
      run: |
        # Check if new data is significantly different from previous
        echo "updated=true" >> $GITHUB_OUTPUT
        
    - name: Version data
      id: version-data
      run: |
        DATA_VERSION=$(date +%Y%m%d_%H%M%S)
        echo "version=$DATA_VERSION" >> $GITHUB_OUTPUT
        
    - name: Upload data artifacts
      uses: actions/upload-artifact@v4
      with:
        name: data-artifacts-${{ steps.version-data.outputs.version }}
        path: |
          artifacts/data_ingestion/
          artifacts/data_validation/
        retention-days: 30

  feature-engineering:
    runs-on: ubuntu-latest
    name: Feature Engineering
    needs: data-ingestion
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Download data artifacts
      uses: actions/download-artifact@v4
      with:
        name: data-artifacts-${{ needs.data-ingestion.outputs.data-version }}
        path: artifacts/
        
    - name: Run feature engineering
      run: |
        export PYTHONPATH=src
        python -c "
        from src.mlpipeline.config.configuration import ConfigurationManager
        from src.mlpipeline.components.feature_engineering import FeatureEngineering
        
        config = ConfigurationManager()
        feature_config = config.get_feature_engineering_config()
        feature_engineering = FeatureEngineering(config=feature_config)
        feature_engineering.engineer_features()
        print('Feature engineering completed successfully')
        "
        
    - name: Upload feature artifacts
      uses: actions/upload-artifact@v4
      with:
        name: feature-artifacts-${{ needs.data-ingestion.outputs.data-version }}
        path: |
          artifacts/feature_engineering/
        retention-days: 30

  model-training:
    runs-on: ubuntu-latest
    name: Model Training & Evaluation
    needs: [data-ingestion, feature-engineering]
    if: needs.data-ingestion.outputs.data-updated == 'true' || github.event.inputs.retrain_model == 'true'
    
    outputs:
      model-version: ${{ steps.version-model.outputs.version }}
      model-accuracy: ${{ steps.evaluate-model.outputs.accuracy }}
      should-deploy: ${{ steps.evaluate-model.outputs.should-deploy }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        name: data-artifacts-${{ needs.data-ingestion.outputs.data-version }}
        path: artifacts/
        
    - name: Download feature artifacts
      uses: actions/download-artifact@v4
      with:
        name: feature-artifacts-${{ needs.data-ingestion.outputs.data-version }}
        path: artifacts/
        
    - name: Run data transformation
      run: |
        export PYTHONPATH=src
        python -c "
        from src.mlpipeline.config.configuration import ConfigurationManager
        from src.mlpipeline.components.data_transformation import DataTransformation
        
        config = ConfigurationManager()
        data_transformation_config = config.get_data_transformation_config()
        data_transformation = DataTransformation(config=data_transformation_config)
        data_transformation.train_test_splitting()
        print('Data transformation completed successfully')
        "
        
    - name: Run model training
      run: |
        export PYTHONPATH=src
        python -c "
        from src.mlpipeline.config.configuration import ConfigurationManager
        from src.mlpipeline.components.model_trainer import ModelTrainer
        
        config = ConfigurationManager()
        model_trainer_config = config.get_model_trainer_config()
        model_trainer = ModelTrainer(config=model_trainer_config)
        model_trainer.train()
        print('Model training completed successfully')
        "
        
    - name: Run model evaluation
      id: evaluate-model
      run: |
        export PYTHONPATH=src
        python -c "
        from src.mlpipeline.config.configuration import ConfigurationManager
        from src.mlpipeline.components.model_evaluation import ModelEvaluation
        import json
        import os
        
        config = ConfigurationManager()
        model_evaluation_config = config.get_model_evaluation_config()
        model_evaluation = ModelEvaluation(config=model_evaluation_config)
        model_evaluation.evaluate()
        
        # Read metrics and determine if we should deploy
        with open('artifacts/model_evaluation/metrics.json', 'r') as f:
            metrics = json.load(f)
        
        accuracy = metrics.get('accuracy', 0)
        should_deploy = accuracy > 0.8  # Deploy if accuracy > 80%
        
        print(f'Model accuracy: {accuracy}')
        print(f'Should deploy: {should_deploy}')
        
        # Set outputs for next steps
        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write(f'accuracy={accuracy}\n')
            f.write(f'should-deploy={should_deploy}\n')
        "
        
    - name: Version model
      id: version-model
      run: |
        MODEL_VERSION=$(date +%Y%m%d_%H%M%S)
        echo "version=$MODEL_VERSION" >> $GITHUB_OUTPUT
        
    - name: Upload model artifacts
      uses: actions/upload-artifact@v4
      with:
        name: model-artifacts-${{ steps.version-model.outputs.version }}
        path: |
          artifacts/model_trainer/
          artifacts/model_evaluation/
          artifacts/data_transformation/
        retention-days: 90

  deploy-model:
    runs-on: ubuntu-latest
    name: Deploy New Model
    needs: model-training
    if: needs.model-training.outputs.should-deploy == 'true'
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download model artifacts
      uses: actions/download-artifact@v4
      with:
        name: model-artifacts-${{ needs.model-training.outputs.model-version }}
        path: artifacts/
        
    - name: Build and push model image
      run: |
        echo "Building Docker image with new model..."
        # docker build -t ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:model-${{ needs.model-training.outputs.model-version }} .
        # docker push ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:model-${{ needs.model-training.outputs.model-version }}
        echo "Model image built and pushed"
        
    - name: Update deployment
      run: |
        echo "Updating Kubernetes deployment with new model..."
        # kubectl set image deployment/ml-pipeline-app ml-pipeline-app=${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:model-${{ needs.model-training.outputs.model-version }}
        # kubectl rollout status deployment/ml-pipeline-app
        echo "Deployment updated with new model"
        
    - name: Run post-deployment tests
      run: |
        echo "Running post-deployment model tests..."
        # Test new model predictions
        echo "Model deployment tests passed"

  model-monitoring:
    runs-on: ubuntu-latest
    name: Setup Model Monitoring
    needs: deploy-model
    if: needs.model-training.outputs.should-deploy == 'true'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Evidently monitoring
      run: |
        echo "Setting up Evidently monitoring for new model..."
        # Configure Evidently with new model baseline
        echo "Model monitoring configured"
        
    - name: Update Grafana dashboards
      run: |
        echo "Updating Grafana dashboards for new model version..."
        # Update dashboards with new model metrics
        echo "Dashboards updated"

  cleanup:
    runs-on: ubuntu-latest
    name: Cleanup Old Artifacts
    needs: [deploy-model, model-monitoring]
    if: always()
    
    steps:
    - name: Cleanup old model artifacts
      run: |
        echo "Cleaning up old model artifacts..."
        # Keep only last 5 model versions
        echo "Cleanup completed"
