# Fluentd configuration for ML Pipeline logging

<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<source>
  @type tail
  path /var/log/ml-pipeline/*.log
  pos_file /var/log/fluentd-ml-pipeline.log.pos
  tag ml.pipeline
  format json
  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S
</source>

<source>
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/fluentd-containers.log.pos
  tag kubernetes.*
  format json
  time_key time
  time_format %Y-%m-%dT%H:%M:%S.%NZ
</source>

<filter ml.pipeline>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

<filter ml.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    tag ${tag}
  </record>
</filter>

<match ml.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix ml-pipeline
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  type_name access_log
  tag_key @log_name
  flush_interval 1s
  <buffer>
    @type file
    path /var/log/fluentd-buffers/ml-pipeline.buffer
    flush_mode interval
    retry_type exponential_backoff
    flush_thread_count 2
    flush_interval 5s
    retry_forever
    retry_max_interval 30
    chunk_limit_size 2M
    queue_limit_length 8
    overflow_action block
  </buffer>
</match>

<match kubernetes.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix kubernetes
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  type_name kubernetes_log
  tag_key @log_name
  flush_interval 1s
</match>

<match **>
  @type stdout
</match>